# Experiment environment
seed: 0
ngpu: 1
num_workers: 1
pin_memory: False
non_blocking: False

# gradient descent related
grad_clip: 5.0
accum_grad: 1

# Training monitoring
train: False
test: True
resume: False

num_epochs: 100
report_per_steps: 10

#valid_per_epochs: 1
best_model_num: 3
best_model_mode: min
best_model_metric: loss
early_stopping_patience: 90
early_stopping_threshold: 0.1
test_model: loss_best

result_path: "/project/nakamura-lab05/Work/novitasari-s/tools/SpeeChain_expr/tts/transformer/ljspeech/inv/base/result/model_TacotronV1Inverter_lrelu_group4"



# Experiment configurations
data_cfg: "/project/nakamura-lab05/Work/novitasari-s/tools/SpeeChain/recipes/tts/ljspeech/data_cfg/sup_mel2raw.yaml"
train_cfg: "/project/nakamura-lab05/Work/novitasari-s/tools/SpeeChain/recipes/tts/ljspeech/vocoder/train_cfg/TacotronV1Inverter_lrelu_group4.yaml"
test_cfg: "/project/nakamura-lab05/Work/novitasari-s/tools/SpeeChain/config/infer/vocoder/base.yaml"
